(window.webpackJsonp=window.webpackJsonp||[]).push([[36],{364:function(s,t,a){"use strict";a.r(t);var e=a(28),r=Object(e.a)({},(function(){var s=this,t=s._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[t("h1",{attrs:{id:"rdb에서-페이징-쿼리의-필요성"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#rdb에서-페이징-쿼리의-필요성"}},[s._v("#")]),s._v(" RDB에서 페이징 쿼리의 필요성")]),s._v(" "),t("ul",[t("li",[s._v("페이징 쿼리는 전체 데이터를 부분적으로 나누어 조회하거나 처리할 때 사용됨")]),s._v(" "),t("li",[s._v("데이터를 상대적으로 작은 단위로 나누어 처리하기 때문에 데이터베이스나 애플리케이션의 사용 효율이 증가함")]),s._v(" "),t("li",[s._v("MySQL에서는 일반적으로 LIMIT, OFFSET 구문을 사용하여 작성")])]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" comments\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("limit")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("500")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("offset")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("h2",{attrs:{id:"limit-offset-방식-페이징-쿼리의-단점과-해결-방법"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#limit-offset-방식-페이징-쿼리의-단점과-해결-방법"}},[s._v("#")]),s._v(" LIMIT, OFFSET 방식 페이징 쿼리의 단점과 해결 방법")]),s._v(" "),t("ul",[t("li",[s._v("LIMIT, OFFSET 방식의 페이징 쿼리는 뒤에 있는 데이터를 읽을수록 점점 응답시간이 길어짐")]),s._v(" "),t("li",[s._v("DBMS에서 지정된 OFFSET 수만큼 모든 레코드를 읽은 이후에 데이터를 가져오기 때문")]),s._v(" "),t("li",[s._v("OFFSET을 사용하지 않는 페이징 쿼리를 사용함으로써 해결 가능")])]),s._v(" "),t("h3",{attrs:{id:"예시"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#예시"}},[s._v("#")]),s._v(" 예시")]),s._v(" "),t("ul",[t("li",[s._v("특정 기간동안 생성된 댓글 조회하는 쿼리")])]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" comments\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v("\n    created_at "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">=")]),s._v(" ? "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("and")]),s._v(" created_at "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),s._v(" ?\n")])])]),t("ul",[t("li",[s._v("OFFSET을 사용하지 않는 페이징은 이전 페이지의 마지막 데이터 값을 기반으로 다음 페이지를 조회")]),s._v(" "),t("li",[s._v("이에 따라 첫 페이지 조회 쿼리와 N 페이지 조회 쿼리가 달라질 수 있음")])]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("-- 첫 페이지")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" comments\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v("\n    created_at "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">=")]),s._v(" ? "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("and")]),s._v(" created_at "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),s._v(" ?\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("order")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("by")]),s._v(" created_at"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" id\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("limit")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),s._v("\n")])])]),t("ul",[t("li",[s._v("첫 페이지 이후의 페이지는 조회된 페이지의 마지막 값을 기반으로 조회")]),s._v(" "),t("li",[s._v("만약 이전 페이지의 마지막 값의 created_at이 '2025-01-01'이고, id가 23이라면")])]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" comments\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("-- created_at이 같은 경우 고려")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("created_at "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'2025-01-01 00:00:00'")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("and")]),s._v(" id "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("23")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("or")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("-- 마지막 데이터 이후 데이터 조회")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("created_at "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'2025-01-01 00:00:00'")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("and")]),s._v(" created_at "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),s._v(" ?"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("order")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("by")]),s._v(" created_at"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" id\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("limit")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),s._v("\n")])])])])}),[],!1,null,null,null);t.default=r.exports}}]);